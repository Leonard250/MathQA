{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":37341.923167,"end_time":"2025-03-06T07:28:55.453190","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-05T21:06:33.530023","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"233b546f4a8c4064a248be8e71f6a781":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_d91fb8d553c9459b93ffcad18518c42d","max":8731128,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cc75fdf547643d3abfc9281580441fe","tabbable":null,"tooltip":null,"value":8731128}},"248bc307319d4735b58f8a661f777020":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_94935a47b232413b85bf18f63e025325","placeholder":"‚Äã","style":"IPY_MODEL_6f48948b7f954bd082439dbf1d9b6150","tabbable":null,"tooltip":null,"value":"README.md:‚Äá100%"}},"24a0458dbfe0434ea71a2735351c22ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24c0cb85be07425b82d7e542342b0cf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"287f2413e9e14518ad769b7effeb7b8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_fa0f10e3149943f88e99c89195fd8ef9","max":5174,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24a0458dbfe0434ea71a2735351c22ed","tabbable":null,"tooltip":null,"value":5174}},"3223f25d75e94dbebe5b0d5eb8ea2b74":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35196408ffa94df19a56b47a8bfbff32":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6217fe258153433e98f237051db7f52d","placeholder":"‚Äã","style":"IPY_MODEL_ddd334b9dc3e445cb3885a243129bc1c","tabbable":null,"tooltip":null,"value":"tokenizer.json:‚Äá100%"}},"3efa470db50848758ebf94ee74a1dfd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35196408ffa94df19a56b47a8bfbff32","IPY_MODEL_f73824deef354f98b511be459c0bdf0c","IPY_MODEL_dac91070dcf1414997ab425b8c1528b0"],"layout":"IPY_MODEL_3223f25d75e94dbebe5b0d5eb8ea2b74","tabbable":null,"tooltip":null}},"43639f6a8d494767a40c21ed00a6c1f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6314d0eb74224b15bfe38da8abd39527","placeholder":"‚Äã","style":"IPY_MODEL_7b7aaeccbcbc43b49f13395bf140b350","tabbable":null,"tooltip":null,"value":"‚Äá8.73M/8.73M‚Äá[00:00&lt;00:00,‚Äá21.2MB/s]"}},"483ee3791ce54a52ae89454f581a1af5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52e760bb1ca640bf83bd725157561d13":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"56c208c75e144408b7b3a391a8f7e3cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_248bc307319d4735b58f8a661f777020","IPY_MODEL_287f2413e9e14518ad769b7effeb7b8a","IPY_MODEL_6aa27b6606044d1ca9b569bec07e5360"],"layout":"IPY_MODEL_8acf779b47864159837945fde9d574ef","tabbable":null,"tooltip":null}},"6217fe258153433e98f237051db7f52d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6314d0eb74224b15bfe38da8abd39527":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aa27b6606044d1ca9b569bec07e5360":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d0dc6030b00e48ba9bdcb1783f5795b2","placeholder":"‚Äã","style":"IPY_MODEL_52e760bb1ca640bf83bd725157561d13","tabbable":null,"tooltip":null,"value":"‚Äá5.17k/5.17k‚Äá[00:00&lt;00:00,‚Äá537kB/s]"}},"6f48948b7f954bd082439dbf1d9b6150":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"78e03993829346bba6daba27070f7191":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b7aaeccbcbc43b49f13395bf140b350":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8acf779b47864159837945fde9d574ef":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9148424de41b4b18939fe7e7ca1f017f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94935a47b232413b85bf18f63e025325":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"978094e8d99b47ff8dbf59257f5d7b05":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cc75fdf547643d3abfc9281580441fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aad6ed27e0fc47a59e06a3caa1c8ffcb":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0726868dfad4a488ca3f7f44ac609d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf17558627b3415d85690e33c08dc8ba","IPY_MODEL_233b546f4a8c4064a248be8e71f6a781","IPY_MODEL_43639f6a8d494767a40c21ed00a6c1f3"],"layout":"IPY_MODEL_78e03993829346bba6daba27070f7191","tabbable":null,"tooltip":null}},"bf17558627b3415d85690e33c08dc8ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_aad6ed27e0fc47a59e06a3caa1c8ffcb","placeholder":"‚Äã","style":"IPY_MODEL_f0a1b1de44dd47a7bccd390af4026910","tabbable":null,"tooltip":null,"value":"adapter_model.safetensors:‚Äá100%"}},"d0dc6030b00e48ba9bdcb1783f5795b2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91fb8d553c9459b93ffcad18518c42d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dac91070dcf1414997ab425b8c1528b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_483ee3791ce54a52ae89454f581a1af5","placeholder":"‚Äã","style":"IPY_MODEL_24c0cb85be07425b82d7e542342b0cf9","tabbable":null,"tooltip":null,"value":"‚Äá11.4M/11.4M‚Äá[00:01&lt;00:00,‚Äá17.9MB/s]"}},"ddd334b9dc3e445cb3885a243129bc1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f0a1b1de44dd47a7bccd390af4026910":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f73824deef354f98b511be459c0bdf0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_9148424de41b4b18939fe7e7ca1f017f","max":11422174,"min":0,"orientation":"horizontal","style":"IPY_MODEL_978094e8d99b47ff8dbf59257f5d7b05","tabbable":null,"tooltip":null,"value":11422174}},"fa0f10e3149943f88e99c89195fd8ef9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d1eef367","cell_type":"code","source":"!pip install flash-attention","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:45:58.922656Z","iopub.execute_input":"2025-03-19T03:45:58.922973Z","iopub.status.idle":"2025-03-19T03:46:03.679497Z","shell.execute_reply.started":"2025-03-19T03:45:58.922947Z","shell.execute_reply":"2025-03-19T03:46:03.678580Z"},"papermill":{"duration":4.683745,"end_time":"2025-03-05T21:06:40.834423","exception":false,"start_time":"2025-03-05T21:06:36.150678","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Collecting flash-attention\n  Downloading flash_attention-1.0.0-py3-none-any.whl.metadata (274 bytes)\nDownloading flash_attention-1.0.0-py3-none-any.whl (31 kB)\nInstalling collected packages: flash-attention\nSuccessfully installed flash-attention-1.0.0\n","output_type":"stream"}],"execution_count":1},{"id":"e8f70ab9","cell_type":"code","source":"!pip install accelerate peft bitsandbytes -q","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:03.680680Z","iopub.execute_input":"2025-03-19T03:46:03.680904Z","iopub.status.idle":"2025-03-19T03:46:09.999920Z","shell.execute_reply.started":"2025-03-19T03:46:03.680883Z","shell.execute_reply":"2025-03-19T03:46:09.998999Z"},"papermill":{"duration":6.148528,"end_time":"2025-03-05T21:06:46.987699","exception":false,"start_time":"2025-03-05T21:06:40.839171","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"id":"9ea422e5","cell_type":"code","source":"# from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n# from transformers.generation import GenerationConfig\n\n# import time\n\n# import torch\n# from torch.cuda.amp import autocast\n\n# import onnx\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# # device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.002244Z","iopub.execute_input":"2025-03-19T03:46:10.002500Z","iopub.status.idle":"2025-03-19T03:46:10.006222Z","shell.execute_reply.started":"2025-03-19T03:46:10.002478Z","shell.execute_reply":"2025-03-19T03:46:10.005332Z"},"papermill":{"duration":0.0105,"end_time":"2025-03-05T21:06:47.003732","exception":false,"start_time":"2025-03-05T21:06:46.993232","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"b0a2d3d6","cell_type":"code","source":"# # model_name = \"Qwen/Qwen2.5-Math-1.5B\"\n# model_name = \"AlgorithmicResearchGroup/flan-t5-base-arxiv-math-question-answering\"\n\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# model = AutoModelForSeq2SeqLM.from_pretrained(\n#     model_name,\n#     device_map=\"auto\",\n#     trust_remote_code=True\n# ).eval()\n\n# model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.007285Z","iopub.execute_input":"2025-03-19T03:46:10.007597Z","iopub.status.idle":"2025-03-19T03:46:10.027851Z","shell.execute_reply.started":"2025-03-19T03:46:10.007566Z","shell.execute_reply":"2025-03-19T03:46:10.027003Z"},"papermill":{"duration":0.009248,"end_time":"2025-03-05T21:06:47.017965","exception":false,"start_time":"2025-03-05T21:06:47.008717","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"208939ec","cell_type":"code","source":"# question = \"What is the total cost of purchasing equipment for all sixteen players on the football team, considering that each player requires a $25 jersey, a $15.20 pair of shorts, and a pair of socks priced at $6.80?\"\n\n# start_time = time.time()\n\n# input_ids = tokenizer(question, return_tensors=\"pt\").input_ids.to(device)\n# output = model.generate(input_ids, max_length=100)\n# response = tokenizer.decode(output[0], skip_special_tokens=True)\n# print(response)\n\n# end_time = time.time()\n# inference_time = end_time - start_time\n# print(f\"\\n\\nInference Time: {inference_time}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.028746Z","iopub.execute_input":"2025-03-19T03:46:10.028989Z","iopub.status.idle":"2025-03-19T03:46:10.043741Z","shell.execute_reply.started":"2025-03-19T03:46:10.028970Z","shell.execute_reply":"2025-03-19T03:46:10.042962Z"},"papermill":{"duration":0.009602,"end_time":"2025-03-05T21:06:47.032642","exception":false,"start_time":"2025-03-05T21:06:47.023040","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"8c7427e5","cell_type":"markdown","source":"# Finetuning the Model","metadata":{"papermill":{"duration":0.004723,"end_time":"2025-03-05T21:06:47.042340","exception":false,"start_time":"2025-03-05T21:06:47.037617","status":"completed"},"tags":[]}},{"id":"d92426b8","cell_type":"markdown","source":"## Tokenize the data","metadata":{"papermill":{"duration":0.004761,"end_time":"2025-03-05T21:06:47.051992","exception":false,"start_time":"2025-03-05T21:06:47.047231","status":"completed"},"tags":[]}},{"id":"39d8af62","cell_type":"code","source":"# from datasets import load_dataset\n\n# dataset = load_dataset(\"meta-math/MetaMathQA\", split=\"train[:1000]\")\n# print(dataset)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.044617Z","iopub.execute_input":"2025-03-19T03:46:10.044809Z","iopub.status.idle":"2025-03-19T03:46:10.058032Z","shell.execute_reply.started":"2025-03-19T03:46:10.044792Z","shell.execute_reply":"2025-03-19T03:46:10.057346Z"},"papermill":{"duration":0.00993,"end_time":"2025-03-05T21:06:47.066752","exception":false,"start_time":"2025-03-05T21:06:47.056822","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"id":"6bf072c2","cell_type":"code","source":"# def tokenize_function(examples):\n#     inputs = examples[\"query\"]\n#     targets = examples[\"response\"]\n\n#     model_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512)\n#     labels = tokenizer(targets, padding=\"max_length\", truncation=True, max_length=512)\n\n#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n#     return model_inputs\n\n# tokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.058814Z","iopub.execute_input":"2025-03-19T03:46:10.058999Z","iopub.status.idle":"2025-03-19T03:46:10.073758Z","shell.execute_reply.started":"2025-03-19T03:46:10.058983Z","shell.execute_reply":"2025-03-19T03:46:10.073110Z"},"papermill":{"duration":0.009208,"end_time":"2025-03-05T21:06:47.081040","exception":false,"start_time":"2025-03-05T21:06:47.071832","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"95354210","cell_type":"code","source":"# tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.074349Z","iopub.execute_input":"2025-03-19T03:46:10.074567Z","iopub.status.idle":"2025-03-19T03:46:10.088812Z","shell.execute_reply.started":"2025-03-19T03:46:10.074521Z","shell.execute_reply":"2025-03-19T03:46:10.088183Z"},"papermill":{"duration":0.009122,"end_time":"2025-03-05T21:06:47.095241","exception":false,"start_time":"2025-03-05T21:06:47.086119","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"d6956d09","cell_type":"markdown","source":"## Training Arguments","metadata":{"papermill":{"duration":0.004683,"end_time":"2025-03-05T21:06:47.104824","exception":false,"start_time":"2025-03-05T21:06:47.100141","status":"completed"},"tags":[]}},{"id":"ccc85ba6","cell_type":"code","source":"# from transformers import TrainingArguments\n\n# training_arguments = TrainingArguments(\n#     output_dir=f\"./{model_name}_finetuned\",\n#     # evaluation_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     per_device_train_batch_size=8,\n#     # per_device_eval_batch_size=4,\n#     gradient_accumulation_steps=8,\n#     num_train_epochs=3,\n#     learning_rate=2e-5,\n#     weight_decay=1e-5,\n#     fp16=True,\n#     save_total_limit=2,\n#     logging_steps=10,\n#     optim=\"adamw_torch_fused\",  # Uses GPU-optimized AdamW\n#     report_to=\"none\"  # Disable logging to WandB if enabled\n# )","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.091212Z","iopub.execute_input":"2025-03-19T03:46:10.091432Z","iopub.status.idle":"2025-03-19T03:46:10.104317Z","shell.execute_reply.started":"2025-03-19T03:46:10.091413Z","shell.execute_reply":"2025-03-19T03:46:10.103554Z"},"papermill":{"duration":0.009462,"end_time":"2025-03-05T21:06:47.119167","exception":false,"start_time":"2025-03-05T21:06:47.109705","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"77430d62","cell_type":"code","source":"# from transformers import Trainer, DataCollatorForSeq2Seq\n\n# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n# trainer = Trainer(\n#     model=model,\n#     args=training_arguments,\n#     train_dataset=tokenized_datasets[\"train\"],\n#     tokenizer=tokenizer,\n#     data_collator=data_collator\n# )","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.105661Z","iopub.execute_input":"2025-03-19T03:46:10.105936Z","iopub.status.idle":"2025-03-19T03:46:10.122678Z","shell.execute_reply.started":"2025-03-19T03:46:10.105907Z","shell.execute_reply":"2025-03-19T03:46:10.121928Z"},"papermill":{"duration":0.009364,"end_time":"2025-03-05T21:06:47.133496","exception":false,"start_time":"2025-03-05T21:06:47.124132","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"ab78c2fe","cell_type":"code","source":"# from peft import get_peft_model, LoraConfig, TaskType\n\n# peft_config = LoraConfig(\n#     task_type=TaskType.CAUSAL_LM,\n#     r=16,\n#     lora_alpha=32,\n#     lora_dropout=0.05\n# )\n\n# model = get_peft_model(model, peft_config)\n# model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.123516Z","iopub.execute_input":"2025-03-19T03:46:10.123829Z","iopub.status.idle":"2025-03-19T03:46:10.139619Z","shell.execute_reply.started":"2025-03-19T03:46:10.123784Z","shell.execute_reply":"2025-03-19T03:46:10.138886Z"},"papermill":{"duration":0.009184,"end_time":"2025-03-05T21:06:47.147679","exception":false,"start_time":"2025-03-05T21:06:47.138495","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"906435e1","cell_type":"code","source":"# from accelerate import Accelerator\n\n# accelerator = Accelerator()\n# model, trainer = accelerator.prepare(model, trainer)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.140485Z","iopub.execute_input":"2025-03-19T03:46:10.140764Z","iopub.status.idle":"2025-03-19T03:46:10.154112Z","shell.execute_reply.started":"2025-03-19T03:46:10.140735Z","shell.execute_reply":"2025-03-19T03:46:10.153488Z"},"papermill":{"duration":0.009314,"end_time":"2025-03-05T21:06:47.161876","exception":false,"start_time":"2025-03-05T21:06:47.152562","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"141a4623","cell_type":"code","source":"script= \"\"\"from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\nfrom datasets import load_dataset\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom accelerate import Accelerator  # Import Accelerator\n\n# Initialize the accelerator\naccelerator = Accelerator()  # Automatically handles device placement\n\n# Use the instruct model variant\nmodel_name = \"Qwen/Qwen2.5-Math-1.5B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\n# Load model without manually specifying the device\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    trust_remote_code=True\n)\n\n# Load dataset\nfull_train_dataset = load_dataset(\"meta-math/MetaMathQA\", split=\"train\")\n\n# Shuffle the dataset to ensure random picking\nshuffled_train_dataset = full_train_dataset.shuffle(seed=42)\n\n# Define the sample size\nsample_size = 70000\n\n# Slice the datasets randomly for training and validation\ntrain_dataset = shuffled_train_dataset.select(range(sample_size))\nvalid_dataset = shuffled_train_dataset.select(range(sample_size, sample_size + 1000))\n\nprint(train_dataset)\nprint(valid_dataset)\n\n# Modified tokenization function using the instruct chat template.\ndef tokenize_function(examples):\n    # Build conversation: system prompt, user query, and assistant response.\n    system_msg = \"Please reason step by step, and put your final answer within \\\\boxed{}.\"\n    inputs = []\n    for query, response in zip(examples[\"query\"], examples[\"response\"]):\n        messages = [\n            {\"role\": \"system\", \"content\": system_msg},\n            {\"role\": \"user\", \"content\": query},\n            {\"role\": \"assistant\", \"content\": response}\n        ]\n        full_text = tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=False  # Include full conversation for training.\n        )\n        inputs.append(full_text)\n    model_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512)\n    # Instead of cloning a tensor, simply assign a copy of the list.\n    model_inputs[\"labels\"] = model_inputs[\"input_ids\"]\n    return model_inputs\n\n\n# Tokenize datasets\ntokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\ntokenized_train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\ntokenized_valid_dataset = valid_dataset.map(tokenize_function, batched=True)\ntokenized_valid_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n# Apply LoRA **before** Trainer initialization\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,  # Correct task type for causal language modeling\n    r=32,  # from 16 to 32\n    lora_alpha=32,\n    lora_dropout=0.1  # from 0.05 to 0.1\n)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()  # Verify that only LoRA parameters are trainable\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=f\"./{model_name}_finetuned\",\n    save_strategy=\"steps\",  # Save every 200 steps\n    evaluation_strategy=\"steps\",  # Evaluate every 200 steps\n    eval_steps=200,  # Check eval every 200 steps\n    per_device_train_batch_size=2,  # Increased batch size\n    per_device_eval_batch_size=1,  # Increased batch size\n    gradient_accumulation_steps=8,  # Slightly reduced gradient accumulation\n    num_train_epochs=3,  # Increased number of epochs\n    learning_rate=5e-4,  # Slightly higher learning rate (from 2e-6)\n    weight_decay=5e-6,  # Slightly reduced weight decay\n    fp16=True,\n    save_total_limit=3,  # Keep 3 checkpoints\n    logging_steps=30,  # Log less frequently\n    optim=\"adamw_torch_fused\",\n    report_to=\"none\"\n)\n\n\n# Data collator\ndata_collator = DataCollatorForSeq2Seq(tokenizer)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_valid_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\n# Start training\ntrainer.train()\n\n# Save the finetuned model and tokenizer\ntrainer.save_model(\"./finetuned-qwen2.5-math\")\ntokenizer.save_pretrained(\"./finetuned-qwen2.5-math\")\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.154926Z","iopub.execute_input":"2025-03-19T03:46:10.155154Z","iopub.status.idle":"2025-03-19T03:46:10.171845Z","shell.execute_reply.started":"2025-03-19T03:46:10.155124Z","shell.execute_reply":"2025-03-19T03:46:10.171106Z"},"papermill":{"duration":0.011031,"end_time":"2025-03-05T21:06:47.177958","exception":false,"start_time":"2025-03-05T21:06:47.166927","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"e0b3f983","cell_type":"code","source":"with open(\"train.py\", \"w\") as f:\n    f.write(script)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.172714Z","iopub.execute_input":"2025-03-19T03:46:10.172999Z","iopub.status.idle":"2025-03-19T03:46:10.191616Z","shell.execute_reply.started":"2025-03-19T03:46:10.172970Z","shell.execute_reply":"2025-03-19T03:46:10.191009Z"},"papermill":{"duration":0.009877,"end_time":"2025-03-05T21:06:47.192844","exception":false,"start_time":"2025-03-05T21:06:47.182967","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"b4c15f5b-403b-4581-a567-3694d3fda4f4","cell_type":"code","source":"!rm -rf ~/.cache/huggingface/datasets/meta-math\n\n!accelerate launch train.py","metadata":{"execution":{"iopub.status.busy":"2025-03-19T03:46:10.192487Z","iopub.execute_input":"2025-03-19T03:46:10.192802Z"},"papermill":{"duration":37304.952381,"end_time":"2025-03-06T07:28:32.283865","exception":false,"start_time":"2025-03-05T21:06:47.331484","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"2025-03-19 03:46:29.074098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-19 03:46:29.074130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-19 03:46:29.342272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-19 03:46:29.342289: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-19 03:46:29.414407: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-03-19 03:46:29.414421: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\ntokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.32k/7.32k [00:00<00:00, 44.7MB/s]\nvocab.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.78M/2.78M [00:00<00:00, 14.6MB/s]\nmerges.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.67M/1.67M [00:00<00:00, 12.1MB/s]\ntokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.03M/7.03M [00:00<00:00, 13.1MB/s]\nconfig.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 656/656 [00:00<00:00, 5.21MB/s]\nmodel.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.09G/3.09G [00:13<00:00, 223MB/s]\ngeneration_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [00:00<00:00, 787kB/s]\nREADME.md: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.45k/4.45k [00:00<00:00, 22.1MB/s]\nMetaMathQA-395K.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 396M/396M [00:01<00:00, 219MB/s]\nGenerating train split: 100%|‚ñà| 395000/395000 [00:10<00:00, 36234.82 examples/s]\nDataset({\n    features: ['type', 'query', 'original_question', 'response'],\n    num_rows: 70000\n})\nDataset({\n    features: ['type', 'query', 'original_question', 'response'],\n    num_rows: 1000\n})\nDataset({\n    features: ['type', 'query', 'original_question', 'response'],\n    num_rows: 70000\n})\nDataset({\n    features: ['type', 'query', 'original_question', 'response'],\n    num_rows: 1000\n})\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70000/70000 [01:07<00:00, 1039.71 examples/s]\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70000/70000 [01:07<00:00, 1039.77 examples/s]\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 1102.79 examples/s]\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 1116.73 examples/s]\ntrainable params: 4,358,144 || all params: 1,548,072,448 || trainable%: 0.2815\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\ntrainable params: 4,358,144 || all params: 1,548,072,448 || trainable%: 0.2815\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/kaggle/working/train.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/kaggle/working/train.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n  0%|                                                  | 0/6561 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n[rank1]:[W319 03:48:42.231843278 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n[rank0]:[W319 03:48:42.237943364 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n{'loss': 8.3063, 'grad_norm': 0.6580427885055542, 'learning_rate': 0.0004977137631458619, 'epoch': 0.01}\n{'loss': 2.1859, 'grad_norm': 0.3569134473800659, 'learning_rate': 0.0004954275262917238, 'epoch': 0.03}\n{'loss': 1.8963, 'grad_norm': 0.3728230893611908, 'learning_rate': 0.0004931412894375858, 'epoch': 0.04}\n  2%|‚ñã                                     | 109/6561 [08:13<8:18:32,  4.64s/it]","output_type":"stream"}],"execution_count":null},{"id":"3b71b4bb","cell_type":"markdown","source":"## Pushing to HuggingFace","metadata":{"papermill":{"duration":0.176414,"end_time":"2025-03-06T07:28:32.660925","exception":false,"start_time":"2025-03-06T07:28:32.484511","status":"completed"},"tags":[]}},{"id":"2a3f9fc2","cell_type":"code","source":"from huggingface_hub import login\n\nhuggingface_token = \"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\"\nlogin(token=huggingface_token)","metadata":{"papermill":{"duration":0.765961,"end_time":"2025-03-06T07:28:33.603406","exception":false,"start_time":"2025-03-06T07:28:32.837445","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"e312e1ae","cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Load the fine-tuned model and tokenizer\nmodel = AutoModelForCausalLM.from_pretrained(\"./finetuned-qwen2.5-math\")\ntokenizer = AutoTokenizer.from_pretrained(\"./finetuned-qwen2.5-math\")\n\n# Define the model's repository name on Hugging Face\nrepo_name = \"Qwen2.5-Math-1.5B-Instruct-Finetuned-MetaMath-v1\"\n\n# Push the model and tokenizer to the Hugging Face Model Hub\nmodel.push_to_hub(repo_name)\ntokenizer.push_to_hub(repo_name)\n","metadata":{"papermill":{"duration":17.526631,"end_time":"2025-03-06T07:28:51.302052","exception":false,"start_time":"2025-03-06T07:28:33.775421","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"0c81d881","cell_type":"markdown","source":"# Checking Memorization","metadata":{"papermill":{"duration":0.165816,"end_time":"2025-03-06T07:28:51.638356","exception":false,"start_time":"2025-03-06T07:28:51.472540","status":"completed"},"tags":[]}},{"id":"b8ae8a1a","cell_type":"code","source":"# from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n# from datasets import load_dataset\n# import torch\n# from peft import get_peft_model, LoraConfig, TaskType\n\n# # Ensure CUDA is available\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# print(\"Using device:\", device)\n\n# # Load Qwen2.5 Math model and tokenizer\n# model_name = f\"Kira-Floris/{repo_name}\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\n# model = AutoModelForCausalLM.from_pretrained(\n#     model_name,\n#     device_map=\"auto\",\n#     trust_remote_code=True\n# ).to(device)\n\n# # Load dataset and take a sample\n# sample_size = 1000\n# train_dataset = load_dataset(\"meta-math/MetaMathQA\", split=f\"train[:{sample_size}]\")\n# valid_dataset = load_dataset(\"meta-math/MetaMathQA\", split=f\"train[{sample_size}:{sample_size+100}]\")\n# print(train_dataset)\n# print(valid_dataset)\n\n# # Tokenization function\n# def tokenize_function(examples):\n#     inputs = examples[\"query\"]\n#     targets = examples[\"response\"]\n    \n#     model_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512)\n#     labels = tokenizer(targets, padding=\"max_length\", truncation=True, max_length=512)\n    \n#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n#     return model_inputs\n\n# # Tokenize dataset\n# tokenized_train_datasets = train_dataset.map(tokenize_function, batched=True)\n# tokenized_train_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])","metadata":{"papermill":{"duration":0.175775,"end_time":"2025-03-06T07:28:51.985026","exception":false,"start_time":"2025-03-06T07:28:51.809251","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"fe2c5513","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.171035,"end_time":"2025-03-06T07:28:52.326944","exception":false,"start_time":"2025-03-06T07:28:52.155909","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}